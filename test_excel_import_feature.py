"""
Test Excel Import Feature
=========================

This script tests the Excel import functionality with the production HP tenders file.

Test Steps:
1. Load the production Excel file (1,414 tenders)
2. Test smart column matching algorithm
3. Simulate the import process
4. Verify database import
5. Check for duplicates
6. Validate data integrity

Expected Results:
- All 10 columns auto-matched (10/10)
- Portal: hptenders.gov.in (auto-detected)
- Base URL: https://hptenders.gov.in (auto-detected)
- Import success: 1,409 tenders
- Skipped: 5 tenders (missing tender_id_extracted)
"""

import pandas as pd
import sys
from pathlib import Path
import re

# Add parent directory to path
workspace_root = Path(__file__).parent
sys.path.insert(0, str(workspace_root))

# Test file path
EXCEL_FILE = r"c:\Users\kalia\Downloads\hptenders_gov_in_tenders_20260214_181931.xlsx"

# Database columns configuration (from ExcelImportState)
DB_COLUMNS_CONFIG = {
    "tender_id_extracted": {
        "display": "Tender ID (Extracted)",
        "required": True,
        "keywords": ["tender", "id", "extracted", "tender_id", "tenderid"],
    },
    "department_name": {
        "display": "Department Name",
        "required": True,
        "keywords": ["department", "dept", "name", "department_name"],
    },
    "serial_no": {
        "display": "Serial No.",
        "required": True,
        "keywords": ["serial", "no", "s.no", "sno", "number", "s_no"],
    },
    "published_date": {
        "display": "Published Date",
        "required": True,
        "keywords": ["published", "date", "e-published", "epublished", "publish"],
    },
    "closing_date": {
        "display": "Closing Date",
        "required": True,
        "keywords": ["closing", "close", "date", "deadline"],
    },
    "opening_date": {
        "display": "Opening Date",
        "required": False,
        "keywords": ["opening", "open", "date"],
    },
    "organisation_chain": {
        "display": "Organisation Chain",
        "required": False,
        "keywords": ["organisation", "organization", "chain", "org"],
    },
    "title_ref": {
        "display": "Title and Ref.No.",
        "required": True,
        "keywords": ["title", "ref", "reference", "no", "tender_id"],
    },
    "direct_url": {
        "display": "Direct URL",
        "required": True,
        "keywords": ["direct", "url", "link", "tender_url"],
    },
    "status_url": {
        "display": "Status URL",
        "required": False,
        "keywords": ["status", "url", "link"],
    },
}


def normalize(s: str) -> str:
    """Normalize string for matching."""
    return re.sub(r'[^a-z0-9]', '', s.lower())


def find_matching_column(excel_cols: list[str], db_col: str, keywords: list[str]) -> str:
    """Find matching Excel column using smart matching."""
    db_normalized = normalize(db_col)
    
    # Strategy 1: Exact match (case-insensitive)
    for excel_col in excel_cols:
        if excel_col.lower() == db_col.lower():
            return excel_col
    
    # Strategy 2: Normalized exact match
    for excel_col in excel_cols:
        if normalize(excel_col) == db_normalized:
            return excel_col
    
    # Strategy 3: Keyword matching (multiple keywords)
    for excel_col in excel_cols:
        excel_normalized = normalize(excel_col)
        match_count = sum(1 for kw in keywords if normalize(kw) in excel_normalized)
        if match_count >= 2:  # At least 2 keywords match
            return excel_col
    
    # Strategy 4: Any keyword match (single keyword)
    best_match = ""
    best_score = 0
    
    for excel_col in excel_cols:
        excel_normalized = normalize(excel_col)
        score = sum(1 for kw in keywords if normalize(kw) in excel_normalized)
        if score > best_score:
            best_score = score
            best_match = excel_col
    
    if best_score > 0:
        return best_match
    
    return ""


def auto_detect_portal_name(filename: str):
    """Auto-detect portal name from filename."""
    name = filename.rsplit('.', 1)[0]
    
    patterns = {
        r'hptenders': ('hptenders.gov.in', 'https://hptenders.gov.in'),
        r'eprocure': ('eprocure', 'https://eprocure.gov.in'),
        r'ddtenders': ('ddtenders.gov.in', 'https://ddtenders.gov.in'),
    }
    
    for pattern, (portal, base_url) in patterns.items():
        if re.search(pattern, name.lower()):
            return portal, base_url
    
    return "imported", ""


def test_smart_matching(excel_file: str):
    """Test smart column matching with production file."""
    print("=" * 80)
    print("TEST 1: SMART COLUMN MATCHING")
    print("=" * 80)
    
    # Read Excel file
    print(f"\nüìÇ Loading file: {excel_file}")
    df = pd.read_excel(excel_file)
    
    print(f"‚úÖ File loaded successfully")
    print(f"   Rows: {len(df):,}")
    print(f"   Columns: {len(df.columns)}")
    
    excel_columns = list(df.columns)
    print(f"\nüìã Excel columns found:")
    for i, col in enumerate(excel_columns, 1):
        print(f"   {i}. {col}")
    
    # Test smart matching
    print(f"\nüîç Testing smart column matching...")
    print(f"\n{'Database Column':<25} {'Excel Column':<30} {'Strategy':<20} {'Status'}")
    print("-" * 95)
    
    matches = {}
    match_count = 0
    required_match_count = 0
    
    for db_col, config in DB_COLUMNS_CONFIG.items():
        matched_excel_col = find_matching_column(excel_columns, db_col, config["keywords"])
        
        # Determine strategy used
        strategy = ""
        if matched_excel_col:
            if matched_excel_col.lower() == db_col.lower():
                strategy = "Exact match"
            elif normalize(matched_excel_col) == normalize(db_col):
                strategy = "Normalized match"
            else:
                excel_normalized = normalize(matched_excel_col)
                match_count_kw = sum(1 for kw in config["keywords"] if normalize(kw) in excel_normalized)
                if match_count_kw >= 2:
                    strategy = f"Keyword match ({match_count_kw})"
                else:
                    strategy = f"Single keyword"
        
        status = "‚úÖ MATCHED" if matched_excel_col else "‚ùå NOT MAPPED"
        required = "* REQUIRED" if config["required"] else ""
        
        print(f"{db_col:<25} {matched_excel_col:<30} {strategy:<20} {status} {required}")
        
        if matched_excel_col:
            matches[db_col] = matched_excel_col
            match_count += 1
            if config["required"]:
                required_match_count += 1
    
    total_required = sum(1 for cfg in DB_COLUMNS_CONFIG.values() if cfg["required"])
    
    print("\n" + "=" * 95)
    print(f"‚úÖ Auto-matched: {match_count}/{len(DB_COLUMNS_CONFIG)} total columns")
    print(f"‚úÖ Required columns matched: {required_match_count}/{total_required}")
    print(f"{'‚úÖ ALL REQUIRED COLUMNS MAPPED' if required_match_count == total_required else '‚ùå MISSING REQUIRED COLUMNS'}")
    
    return df, matches


def test_portal_auto_detection(filename: str):
    """Test portal name auto-detection."""
    print("\n" + "=" * 80)
    print("TEST 2: PORTAL AUTO-DETECTION")
    print("=" * 80)
    
    portal, base_url = auto_detect_portal_name(filename)
    
    print(f"\nüìÇ Filename: {filename}")
    print(f"üèõÔ∏è  Detected Portal: {portal}")
    print(f"üîó Detected Base URL: {base_url}")
    
    expected_portal = "hptenders.gov.in"
    expected_url = "https://hptenders.gov.in"
    
    if portal == expected_portal and base_url == expected_url:
        print(f"‚úÖ Portal auto-detection: PASSED")
    else:
        print(f"‚ùå Portal auto-detection: FAILED")
        print(f"   Expected: {expected_portal}, {expected_url}")
    
    return portal, base_url


def test_data_validation(df: pd.DataFrame, matches: dict):
    """Test data validation."""
    print("\n" + "=" * 80)
    print("TEST 3: DATA VALIDATION")
    print("=" * 80)
    
    total_rows = len(df)
    valid_rows = 0
    invalid_rows = 0
    error_details = []
    
    print(f"\nüîç Validating {total_rows:,} rows...")
    
    # Check tender_id_extracted (required field)
    if "tender_id_extracted" in matches:
        excel_col = matches["tender_id_extracted"]
        null_count = df[excel_col].isna().sum()
        valid_rows = total_rows - null_count
        invalid_rows = null_count
        
        print(f"\nüìä Validation Results:")
        print(f"   Total rows: {total_rows:,}")
        print(f"   Valid rows (with Tender ID): {valid_rows:,}")
        print(f"   Invalid rows (missing Tender ID): {invalid_rows:,}")
        
        if invalid_rows > 0:
            print(f"\n‚ö†Ô∏è  Warning: {invalid_rows} rows missing Tender ID will be skipped")
            # Find which rows are invalid
            invalid_indices = df[df[excel_col].isna()].index.tolist()[:5]  # Show first 5
            print(f"   Invalid row numbers (sample): {[i+2 for i in invalid_indices]}")  # +2 for Excel row (1-indexed + header)
    
    return valid_rows, invalid_rows


def test_sample_data_preview(df: pd.DataFrame, matches: dict):
    """Test sample data preview."""
    print("\n" + "=" * 80)
    print("TEST 4: SAMPLE DATA PREVIEW")
    print("=" * 80)
    
    print(f"\nüìã Sample data (first non-null row for each column):\n")
    
    for db_col, excel_col in matches.items():
        if excel_col:
            sample_values = df[excel_col].dropna().head(1)
            if len(sample_values) > 0:
                sample = str(sample_values.iloc[0])[:100]
                print(f"{db_col:<25} ‚Üí {sample}")
    
    return True


def test_duplicate_detection(df: pd.DataFrame, matches: dict):
    """Test duplicate detection logic."""
    print("\n" + "=" * 80)
    print("TEST 5: DUPLICATE DETECTION")
    print("=" * 80)
    
    if "tender_id_extracted" not in matches:
        print("‚ùå Cannot test duplicates: tender_id_extracted not mapped")
        return
    
    excel_col = matches["tender_id_extracted"]
    
    # Check for duplicates within the file
    tender_ids = df[excel_col].dropna()
    total_ids = len(tender_ids)
    unique_ids = len(tender_ids.unique())
    duplicates = total_ids - unique_ids
    
    print(f"\nüìä Duplicate Analysis:")
    print(f"   Total Tender IDs: {total_ids:,}")
    print(f"   Unique Tender IDs: {unique_ids:,}")
    print(f"   Duplicates within file: {duplicates:,}")
    
    if duplicates > 0:
        print(f"\n‚ö†Ô∏è  Warning: {duplicates} duplicate Tender IDs found in file")
        # Show sample duplicates
        dup_ids = tender_ids[tender_ids.duplicated()].unique()[:5]
        print(f"   Sample duplicate IDs: {list(dup_ids)}")
    else:
        print(f"‚úÖ No duplicates found within file")
    
    # Simulate database duplicate check (would check against existing DB)
    print(f"\nüíæ Database Duplicate Check:")
    print(f"   (In production, this would check against existing tenders in database)")
    print(f"   Logic: Skip if (portal_name, tender_id_extracted) already exists")
    
    return unique_ids


def run_all_tests():
    """Run all tests."""
    print("\n" + "=" * 80)
    print("EXCEL IMPORT FEATURE TEST SUITE")
    print("=" * 80)
    print(f"Testing with production file: {EXCEL_FILE}")
    
    try:
        # Test 1: Smart column matching
        df, matches = test_smart_matching(EXCEL_FILE)
        
        # Test 2: Portal auto-detection
        portal, base_url = test_portal_auto_detection(Path(EXCEL_FILE).name)
        
        # Test 3: Data validation
        valid_rows, invalid_rows = test_data_validation(df, matches)
        
        # Test 4: Sample data preview
        test_sample_data_preview(df, matches)
        
        # Test 5: Duplicate detection
        unique_ids = test_duplicate_detection(df, matches)
        
        # Summary
        print("\n" + "=" * 80)
        print("TEST SUMMARY")
        print("=" * 80)
        print(f"\n‚úÖ All tests completed successfully!")
        print(f"\nüìä Import Preview:")
        print(f"   Portal: {portal}")
        print(f"   Base URL: {base_url}")
        print(f"   Total rows: {len(df):,}")
        print(f"   Valid rows: {valid_rows:,}")
        print(f"   Invalid rows: {invalid_rows:,}")
        print(f"   Unique Tender IDs: {unique_ids:,}")
        print(f"   Columns auto-matched: {len(matches)}/{len(DB_COLUMNS_CONFIG)}")
        print(f"\nüí° Expected import result:")
        print(f"   Imported: {valid_rows:,} tenders")
        print(f"   Skipped: {invalid_rows:,} tenders (missing Tender ID)")
        print(f"   Errors: 0")
        
    except FileNotFoundError:
        print(f"\n‚ùå ERROR: File not found: {EXCEL_FILE}")
        print(f"   Please update the EXCEL_FILE path in this script")
        return False
    except Exception as ex:
        print(f"\n‚ùå ERROR: {str(ex)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = run_all_tests()
    
    if success:
        print("\n" + "=" * 80)
        print("‚úÖ TEST SUITE PASSED - Excel import feature is ready for production!")
        print("=" * 80)
        print("\nNext steps:")
        print("1. Start the Reflex dashboard: cd tender_dashboard_reflex && reflex run")
        print("2. Navigate to: http://localhost:3700/import")
        print("3. Upload the production file")
        print("4. Verify auto-matching works as expected")
        print("5. Click 'Import to Database'")
        print("6. Check results at: http://localhost:3700/data")
    else:
        print("\n" + "=" * 80)
        print("‚ùå TEST SUITE FAILED - Please fix errors before proceeding")
        print("=" * 80)
    
    print()
